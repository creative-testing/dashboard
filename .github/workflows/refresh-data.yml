name: ðŸ¤– Auto Refresh Data

on:
  schedule:
    # Toutes les 2 heures (UTC times)
    # Mexico City est UTC-6, donc on ajuste
    - cron: '0 12,14,16,18,20,22,0,2,4 * * *'  # 6h,8h,10h,12h,14h,16h,18h,20h,22h Mexico
    # Nightly pour late attribution (7 jours)
    - cron: '0 3 * * *'  # 3am UTC = 9pm Mexico (une fois par nuit)
    
  workflow_dispatch:  # Permet de lancer manuellement depuis GitHub

jobs:
  refresh-data:
    runs-on: ubuntu-latest
    concurrency:
      group: refresh-data
      cancel-in-progress: true
    permissions:
      contents: write  # Allow push to repository
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: ðŸ”„ Smart baseline recovery
      run: |
        echo "ðŸ” Checking for existing data..."
        
        # Try 1: Check GitHub Pages for existing data
        if curl -f -s https://fred1433.github.io/creative-testing-dashboard/data/optimized/manifest.json > /dev/null; then
          ads_count=$(curl -s https://fred1433.github.io/creative-testing-dashboard/data/optimized/manifest.json | python3 -c "import json,sys; print(json.load(sys.stdin).get('ads_count', 0))")
          echo "ðŸŒ GitHub has $ads_count ads"
          
          # If we have substantial data, create a marker
          if [ "$ads_count" -gt "1000" ]; then
            echo "âœ… Good data found, will use smart fetch"
            echo "SMART_FETCH_DAYS=30" >> $GITHUB_ENV
          else
            echo "âš ï¸ Limited data, will bootstrap with 7 days"
            echo "SMART_FETCH_DAYS=7" >> $GITHUB_ENV
          fi
        else
          echo "ðŸ†• No existing data, bootstrapping with 14 days"
          echo "SMART_FETCH_DAYS=14" >> $GITHUB_ENV
        fi
        
        # Create baseline directory
        mkdir -p data/current
        echo '{"daily_ads": [], "metadata": {}}' > data/current/baseline_90d_daily.json
    
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests python-dotenv
    
    - name: ðŸ“Š Run Daily Refresh
      env:
        FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
        FRESHNESS_BUFFER_HOURS: 2
        # Smart fetch: more days if no baseline, less if we have data
        TAIL_BACKFILL_DAYS: ${{ env.SMART_FETCH_DAYS || (github.event.schedule == '0 3 * * *' && '7' || '1') }}
        RUN_BASELINE: 0
      timeout-minutes: 30
      run: |
        if [[ "${{ github.event.schedule }}" == "0 3 * * *" ]]; then
          echo "ðŸŒ™ Running nightly refresh (7 days for late attribution)..."
        else
          echo "ðŸš€ Running daily refresh (1 day)..."
        fi
        python3 scripts/production/fetch_with_smart_limits.py
    
    - name: ðŸ—œï¸ Compress data
      if: success()
      run: |
        echo "Compressing data..."
        python3 scripts/transform_to_columnar.py
    
    - name: ðŸ’¾ Save baseline to cache
      if: success()
      uses: actions/cache/save@v4
      with:
        path: data/current/baseline_90d_daily.json
        key: baseline-${{ github.ref_name }}-${{ github.run_id }}
    
    - name: ðŸ“‹ Copy to dashboard
      if: success()
      run: |
        mkdir -p docs/data
        rm -rf docs/data/optimized
        mkdir -p docs/data/optimized
        cp data/optimized/*.json docs/data/optimized/ 2>/dev/null || echo "No optimized files to copy yet"
        # Ensure prev_week file exists (even if empty)
        if [ ! -f docs/data/optimized/prev_week_compressed.json ]; then
          echo '{"period":"prev_week","ads":[]}' > docs/data/optimized/prev_week_compressed.json
        fi
    
    - name: ðŸ“¤ Commit and push changes
      if: success()
      run: |
        git config --global user.name "GitHub Actions Bot"
        git config --global user.email "actions@github.com"
        
        git add -f docs/data/optimized/*.json
        # Also add prev_week if it exists
        git add -f docs/data/optimized/prev_week_compressed.json 2>/dev/null || true
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ðŸ¤– Auto-refresh: $(date '+%Y-%m-%d %H:%M') UTC (${{ env.MODE }} mode)"
          
          # Pull before push to handle conflicts
          git pull --rebase origin master || git pull --no-rebase origin master
          
          # Push with retry logic
          for i in 1 2 3; do
            git push && break
            echo "Push attempt $i failed, retrying..."
            sleep 2
            git pull --rebase origin master || git pull --no-rebase origin master
          done
        fi
    
    - name: ðŸ“Š Report status
      if: always()
      run: |
        echo "Refresh completed with status: ${{ job.status }}"
        echo "Mode: Daily (1 day)"
        echo "Time: $(date '+%Y-%m-%d %H:%M:%S') UTC"