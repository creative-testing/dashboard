name: ðŸš€ Fast Deploy (Code Only)

on:
  push:
    branches: [ master ]
    paths:
      - 'docs/**/*.html'
      - 'docs/**/*.js'
      - 'docs/**/*.css'
      - 'docs/data/demographics/**'
  workflow_dispatch:
  workflow_run:
    workflows: ["ðŸ“Š Fetch Demographics (Age/Gender)", "ðŸ¤– Auto Refresh Data"]
    types: [completed]
    branches: [master]

permissions:
  contents: read
  actions: read
  pages: write
  id-token: write

concurrency:
  group: pages-deploy
  cancel-in-progress: false  # JAMAIS annuler pour Ã©viter les 404

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: ðŸ“¥ Checkout repo (master)
        uses: actions/checkout@v4

      - name: ðŸ§° Install tooling
        run: sudo apt-get update && sudo apt-get install -y jq unzip

      - name: ðŸ“¦ RÃ©cupÃ©rer le dernier site Pages publiÃ© (si disponible)
        run: |
          set -e
          mkdir -p _site_prev
          # On ne cherche plus dans refresh-data car il ne dÃ©ploie plus !
          # Seul deploy-fast publie maintenant
          RUN_ID=$(gh run list --workflow ".github/workflows/deploy-fast.yml" --json databaseId,conclusion -L 20 \
            | jq -r '[.[]|select(.conclusion=="success")][0].databaseId // empty')

          if [ -n "$RUN_ID" ]; then
            echo "â„¹ï¸ TÃ©lÃ©chargement artefact Pages du run $RUN_IDâ€¦"
            # IMPORTANT: Ne pas faire Ã©chouer si l'artefact n'existe pas (2>/dev/null et || true)
            gh run download "$RUN_ID" -n github-pages -D _site_prev 2>/dev/null || echo "â„¹ï¸ Pas d'artefact (normal au dÃ©but)"
            if compgen -G "_site_prev/*.zip" > /dev/null 2>/dev/null; then
              unzip -q _site_prev/*.zip -d _site_prev/extracted
              rm -f _site_prev/*.zip
              shopt -s dotglob; mv _site_prev/extracted/* _site_prev/ || true
            fi
          else
            echo "âš ï¸ Aucun dÃ©ploiement prÃ©cÃ©dent trouvÃ© (normal au dÃ©but)"
          fi

      - name: ðŸ§± Construire le bundle final (prÃ©server data/, mettre Ã  jour le code)
        run: |
          set -e
          mkdir -p _site
          if [ -d "_site_prev" ] && [ -n "$(ls -A _site_prev 2>/dev/null)" ]; then
            cp -a _site_prev/. _site/
          else
            cp -a docs/. _site/
          fi
          # Met Ã  jour uniquement HTML/JS/CSS depuis le repo (NE TOUCHE PAS aux data optimisÃ©es)
          rsync -a \
            --include="*/" \
            --include="**/*.html" --include="**/*.js" --include="**/*.css" \
            --exclude="docs/data/optimized/**" \
            --exclude="*" \
            docs/ _site/

      - name: ðŸ“Š Overlay demographics (repo â†’ _site)
        run: |
          if [ -d "docs/data/demographics" ]; then
            mkdir -p _site/data/demographics
            rsync -a docs/data/demographics/ _site/data/demographics/
            echo "âœ… Demographics copiÃ©s vers _site/ (fast deploy)"
          else
            echo "â„¹ï¸ Aucun docs/data/demographics dans le repo"
          fi

      - name: ðŸ§ª Valider/Bootstrapper les donnÃ©es (baseline â†’ transform â†’ fallback vide)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e

          have_data() {
            [ -s "_site/data/optimized/meta_v1.json" ] && [ -s "_site/data/optimized/agg_v1.json" ]
          }

          # 0) Si l'artefact Pages a dÃ©jÃ  les data optimisÃ©es â†’ OK
          if have_data; then
            echo "âœ… DonnÃ©es optimisÃ©es dÃ©jÃ  prÃ©sentes"
            exit 0
          fi

          echo "â„¹ï¸ Pas de donnÃ©es optimisÃ©es. Tentative de bootstrapâ€¦"
          mkdir -p data/current data/optimized

          # 1) Tenter la reconstruction depuis le Release 'baseline'
          if gh release view "baseline" >/dev/null 2>&1; then
            echo "â¬‡ï¸ TÃ©lÃ©chargement baseline_90d_daily.json.zstâ€¦"
            if gh release download "baseline" -p "baseline_90d_daily.json.zst" -D data/current --clobber; then
              sudo apt-get update -y >/dev/null 2>&1
              sudo apt-get install -y zstd >/dev/null 2>&1
              zstd -d -f "data/current/baseline_90d_daily.json.zst" -o "data/current/baseline_90d_daily.json"

              # (Optionnel mais propre) disposer d'un Python rÃ©cent
              echo "::group::Python"
              python3 -V || true
              echo "::endgroup::"

              echo "ðŸ”„ Transform â†’ format optimisÃ©"
              python3 scripts/transform_to_columnar.py --input-dir data/current --output-dir data/optimized || true
            else
              echo "âš ï¸ Ã‰chec tÃ©lÃ©chargement baseline."
            fi
          else
            echo "â„¹ï¸ Aucun Release 'baseline' trouvÃ©."
          fi

          # 2) Fallback final : gÃ©nÃ©rer des JSON **valides** (schema-valid) si besoin
          if [ ! -s "data/optimized/meta_v1.json" ] || [ ! -s "data/optimized/agg_v1.json" ]; then
            echo "ðŸ§ª Fallback: gÃ©nÃ©ration de JSON optimisÃ©s vides (schema-valid)â€¦"
            REF_DATE="$(date -u -d 'yesterday' +%F 2>/dev/null || date -u +%F)"
            NOW="$(date -u +%FT%TZ)"
            mkdir -p data/optimized

            cat > data/optimized/meta_v1.json <<JSON
          {"version":1,"metadata":{"reference_date":"$REF_DATE","reference_hour":"$NOW","buffer_hours":0,"includes_today":false,"data_min_date":"$REF_DATE","data_max_date":"$REF_DATE","data_range_days":1,"last_update":"$NOW","source":"bootstrap_empty","pipeline":"bootstrap"},"ads":[],"campaigns":{},"adsets":{},"accounts":{}}
          JSON

            cat > data/optimized/agg_v1.json <<'JSON'
          {"version":1,"periods":["3d","7d","14d","30d","90d"],"metrics":["impressions","clicks","purchases","spend","purchase_value","reach"],"ads":[],"values":[],"scales":{"money":100}}
          JSON

            cat > data/optimized/summary_v1.json <<'JSON'
          {"periods":["3d","7d","14d","30d","90d"],"totals":{"3d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"7d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"14d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"30d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"90d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0}}}
          JSON

            cat > data/optimized/manifest.json <<JSON
          {"version":"$NOW","ads_count":0,"periods":["3d","7d","14d","30d","90d"],"shards":{"meta":{"path":"meta_v1.json"},"agg":{"path":"agg_v1.json"},"summary":{"path":"summary_v1.json"}}}
          JSON

            echo '{"period":"prev_week","ads":[]}' > data/optimized/prev_week_compressed.json
          fi

          # 3) Copier vers le bundle final et sanity-check
          mkdir -p _site/data/optimized
          cp -a data/optimized/. _site/data/optimized/
          if [ ! -s "_site/data/optimized/meta_v1.json" ] || [ ! -s "_site/data/optimized/agg_v1.json" ]; then
            echo "âŒ Impossible de prÃ©parer des donnÃ©es valides pour le dÃ©ploiement."
            exit 1
          fi
          echo "âœ… DonnÃ©es prÃªtes (baseline/empty fallback)."
          ls -la _site/data/optimized || true

      - name: ðŸ”Ž Sanity check (no empty site!)
        run: |
          test -s _site/index_full.html || (echo "âŒ index_full.html is empty or missing!" && exit 1)
          test -s _site/data/optimized/meta_v1.json || (echo "âŒ meta_v1.json is empty or missing!" && exit 1)
          echo "âœ… Site content verified"

      - name: ðŸ”§ Setup Pages
        uses: actions/configure-pages@v5

      - name: ðŸ“¦ Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: _site

      - name: ðŸš€ Deploy to Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: ðŸŒ¬ï¸ Smoke check (200 OK)
        run: |
          sleep 8
          URL="${{ steps.deployment.outputs.page_url }}"
          # Remove trailing slash if present
          URL="${URL%/}"
          curl -sSfL "${URL}/index_full.html" >/dev/null
          echo "âœ… Site is responding correctly (200 OK)"

      - name: âœ… Summary
        run: |
          echo "## ðŸš€ Fast Deploy Complete" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY