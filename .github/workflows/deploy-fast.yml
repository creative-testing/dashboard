name: 🚀 Fast Deploy (Code Only)

on:
  push:
    branches: [ master ]
    paths:
      - 'docs/**/*.html'
      - 'docs/**/*.js'
      - 'docs/**/*.css'
      - 'docs/data/demographics/**'
  workflow_dispatch:
  workflow_run:
    workflows: ["📊 Fetch Demographics (Age/Gender)", "🤖 Auto Refresh Data"]
    types: [completed]
    branches: [master]

permissions:
  contents: read
  actions: read
  pages: write
  id-token: write

concurrency:
  group: pages-deploy
  cancel-in-progress: false  # JAMAIS annuler pour éviter les 404

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: 📥 Checkout repo (master)
        uses: actions/checkout@v4

      - name: 🧰 Install tooling
        run: sudo apt-get update && sudo apt-get install -y jq unzip

      - name: 📦 Récupérer le dernier site Pages publié (si disponible)
        run: |
          set -e
          mkdir -p _site_prev
          # On ne cherche plus dans refresh-data car il ne déploie plus !
          # Seul deploy-fast publie maintenant
          RUN_ID=$(gh run list --workflow ".github/workflows/deploy-fast.yml" --json databaseId,conclusion -L 20 \
            | jq -r '[.[]|select(.conclusion=="success")][0].databaseId // empty')

          if [ -n "$RUN_ID" ]; then
            echo "ℹ️ Téléchargement artefact Pages du run $RUN_ID…"
            # IMPORTANT: Ne pas faire échouer si l'artefact n'existe pas (2>/dev/null et || true)
            gh run download "$RUN_ID" -n github-pages -D _site_prev 2>/dev/null || echo "ℹ️ Pas d'artefact (normal au début)"
            if compgen -G "_site_prev/*.zip" > /dev/null 2>/dev/null; then
              unzip -q _site_prev/*.zip -d _site_prev/extracted
              rm -f _site_prev/*.zip
              shopt -s dotglob; mv _site_prev/extracted/* _site_prev/ || true
            fi
          else
            echo "⚠️ Aucun déploiement précédent trouvé (normal au début)"
          fi

      - name: 🧱 Construire le bundle final (préserver data/, mettre à jour le code)
        run: |
          set -e
          mkdir -p _site
          if [ -d "_site_prev" ] && [ -n "$(ls -A _site_prev 2>/dev/null)" ]; then
            cp -a _site_prev/. _site/
          else
            cp -a docs/. _site/
          fi
          # Met à jour uniquement HTML/JS/CSS depuis le repo (NE TOUCHE PAS aux data optimisées)
          rsync -a \
            --include="*/" \
            --include="**/*.html" --include="**/*.js" --include="**/*.css" \
            --exclude="docs/data/optimized/**" \
            --exclude="*" \
            docs/ _site/

      - name: 📊 Overlay demographics (repo → _site)
        run: |
          if [ -d "docs/data/demographics" ]; then
            mkdir -p _site/data/demographics
            rsync -a docs/data/demographics/ _site/data/demographics/
            echo "✅ Demographics copiés vers _site/ (fast deploy)"
          else
            echo "ℹ️ Aucun docs/data/demographics dans le repo"
          fi

      - name: 🧪 Valider/Bootstrapper les données (baseline → transform → fallback vide)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e

          have_data() {
            [ -s "_site/data/optimized/meta_v1.json" ] && [ -s "_site/data/optimized/agg_v1.json" ]
          }

          # 0) Si l'artefact Pages a déjà les data optimisées → OK
          if have_data; then
            echo "✅ Données optimisées déjà présentes"
            exit 0
          fi

          echo "ℹ️ Pas de données optimisées. Tentative de bootstrap…"
          mkdir -p data/current data/optimized

          # 1) Tenter la reconstruction depuis le Release 'baseline'
          if gh release view "baseline" >/dev/null 2>&1; then
            echo "⬇️ Téléchargement baseline_90d_daily.json.zst…"
            if gh release download "baseline" -p "baseline_90d_daily.json.zst" -D data/current --clobber; then
              sudo apt-get update -y >/dev/null 2>&1
              sudo apt-get install -y zstd >/dev/null 2>&1
              zstd -d -f "data/current/baseline_90d_daily.json.zst" -o "data/current/baseline_90d_daily.json"

              # (Optionnel mais propre) disposer d'un Python récent
              echo "::group::Python"
              python3 -V || true
              echo "::endgroup::"

              echo "🔄 Transform → format optimisé"
              python3 scripts/transform_to_columnar.py --input-dir data/current --output-dir data/optimized || true
            else
              echo "⚠️ Échec téléchargement baseline."
            fi
          else
            echo "ℹ️ Aucun Release 'baseline' trouvé."
          fi

          # 2) Fallback final : générer des JSON **valides** (schema-valid) si besoin
          if [ ! -s "data/optimized/meta_v1.json" ] || [ ! -s "data/optimized/agg_v1.json" ]; then
            echo "🧪 Fallback: génération de JSON optimisés vides (schema-valid)…"
            REF_DATE="$(date -u -d 'yesterday' +%F 2>/dev/null || date -u +%F)"
            NOW="$(date -u +%FT%TZ)"
            mkdir -p data/optimized

            cat > data/optimized/meta_v1.json <<JSON
          {"version":1,"metadata":{"reference_date":"$REF_DATE","reference_hour":"$NOW","buffer_hours":0,"includes_today":false,"data_min_date":"$REF_DATE","data_max_date":"$REF_DATE","data_range_days":1,"last_update":"$NOW","source":"bootstrap_empty","pipeline":"bootstrap"},"ads":[],"campaigns":{},"adsets":{},"accounts":{}}
          JSON

            cat > data/optimized/agg_v1.json <<'JSON'
          {"version":1,"periods":["3d","7d","14d","30d","90d"],"metrics":["impressions","clicks","purchases","spend","purchase_value","reach"],"ads":[],"values":[],"scales":{"money":100}}
          JSON

            cat > data/optimized/summary_v1.json <<'JSON'
          {"periods":["3d","7d","14d","30d","90d"],"totals":{"3d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"7d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"14d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"30d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0},"90d":{"impr":0,"clk":0,"purch":0,"spend_cents":0,"purchase_value_cents":0,"reach":0}}}
          JSON

            cat > data/optimized/manifest.json <<JSON
          {"version":"$NOW","ads_count":0,"periods":["3d","7d","14d","30d","90d"],"shards":{"meta":{"path":"meta_v1.json"},"agg":{"path":"agg_v1.json"},"summary":{"path":"summary_v1.json"}}}
          JSON

            echo '{"period":"prev_week","ads":[]}' > data/optimized/prev_week_compressed.json
          fi

          # 3) Copier vers le bundle final et sanity-check
          mkdir -p _site/data/optimized
          cp -a data/optimized/. _site/data/optimized/
          if [ ! -s "_site/data/optimized/meta_v1.json" ] || [ ! -s "_site/data/optimized/agg_v1.json" ]; then
            echo "❌ Impossible de préparer des données valides pour le déploiement."
            exit 1
          fi
          echo "✅ Données prêtes (baseline/empty fallback)."
          ls -la _site/data/optimized || true

      - name: 🔎 Sanity check (no empty site!)
        run: |
          test -s _site/index_full.html || (echo "❌ index_full.html is empty or missing!" && exit 1)
          test -s _site/data/optimized/meta_v1.json || (echo "❌ meta_v1.json is empty or missing!" && exit 1)
          echo "✅ Site content verified"

      - name: 🔧 Setup Pages
        uses: actions/configure-pages@v5

      - name: 📦 Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: _site

      - name: 🚀 Deploy to Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: 🌬️ Smoke check (200 OK)
        run: |
          sleep 8
          URL="${{ steps.deployment.outputs.page_url }}"
          # Remove trailing slash if present
          URL="${URL%/}"
          curl -sSfL "${URL}/index_full.html" >/dev/null
          echo "✅ Site is responding correctly (200 OK)"

      - name: ✅ Summary
        run: |
          echo "## 🚀 Fast Deploy Complete" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY